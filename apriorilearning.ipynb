{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import apyori as ap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importation of dataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records:  7501\n"
     ]
    }
   ],
   "source": [
    "# import dataset\n",
    "movies = pd.read_csv(\"movie_dataset.csv\", header=None)\n",
    "nums_records = len(movies)\n",
    "print(\"Number of records: \", nums_records)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this part we will convert our dataframe to a list so we can pass it as a param in apriori function\n",
    "### And removing nan value to prevent to have an association with 'nan'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The Revenant', '13 Hours', 'Allied', 'Zootopia', 'Jigsaw', 'Achorman', 'Grinch', 'Fast and Furious', 'Ghostbusters', 'Wolverine', 'Mad Max', 'John Wick', 'La La Land', 'The Good Dunosaur', 'Ninja Turtles', 'The Good Dunosaur Bad Moms', '2 Guns', 'Inside Out', 'Valerian', 'Spiderman 3']\n"
     ]
    }
   ],
   "source": [
    "movies_list = []\n",
    "# convert the dataset into a list of lists of strings\n",
    "for transaction in range(0 , nums_records):\n",
    "    # append each movie to the list of movies and remove nan values\n",
    "    movies_list.append([str(movies.values[transaction,movie]) for movie in range(0,20) if str(movies.values[transaction,movie]) != 'nan'])\n",
    "print(movies_list[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use of apriori algorithm to find the most frequent movies association in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RelationRecord(items=frozenset({'Green Lantern', 'Red Sparrow'}), support=0.005732568990801226, ordered_statistics=[OrderedStatistic(items_base=frozenset({'Red Sparrow'}), items_add=frozenset({'Green Lantern'}), confidence=0.3006993006993007, lift=3.790832696715049)]), RelationRecord(items=frozenset({'Green Lantern', 'Star Wars'}), support=0.005865884548726837, ordered_statistics=[OrderedStatistic(items_base=frozenset({'Star Wars'}), items_add=frozenset({'Green Lantern'}), confidence=0.3728813559322034, lift=4.700811850163794)]), RelationRecord(items=frozenset({'Kung Fu Panda', 'Jumanji'}), support=0.015997866951073192, ordered_statistics=[OrderedStatistic(items_base=frozenset({'Kung Fu Panda'}), items_add=frozenset({'Jumanji'}), confidence=0.3234501347708895, lift=3.2919938411349285)]), RelationRecord(items=frozenset({'Wonder Woman', 'Jumanji'}), support=0.005332622317024397, ordered_statistics=[OrderedStatistic(items_base=frozenset({'Wonder Woman'}), items_add=frozenset({'Jumanji'}), confidence=0.3773584905660377, lift=3.840659481324083)]), RelationRecord(items=frozenset({'Spiderman 3', 'The Spy Who Dumped Me'}), support=0.007998933475536596, ordered_statistics=[OrderedStatistic(items_base=frozenset({'The Spy Who Dumped Me'}), items_add=frozenset({'Spiderman 3'}), confidence=0.2714932126696833, lift=4.122410097642296)])]\n"
     ]
    }
   ],
   "source": [
    "# apply apriori algorithm to the dataset\n",
    "association_rules = ap.apriori(\n",
    "    movies_list, min_support=0.0053, min_confidence=0.2, min_lift=3, max_length=2\n",
    ")\n",
    "# convert the rules into a list\n",
    "association_results = list(association_rules)\n",
    "\n",
    "print(association_results)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract the rules and their confidence,support and lift from the apriori result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              base_items      add_items   support  confidence      lift\n",
      "0            Red Sparrow  Green Lantern  0.005733    0.300699  3.790833\n",
      "1              Star Wars  Green Lantern  0.005866    0.372881  4.700812\n",
      "2          Kung Fu Panda        Jumanji  0.015998    0.323450  3.291994\n",
      "3           Wonder Woman        Jumanji  0.005333    0.377358  3.840659\n",
      "4  The Spy Who Dumped Me    Spiderman 3  0.007999    0.271493  4.122410\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for record in association_results:\n",
    "    for ordered_stat in record.ordered_statistics:\n",
    "        items_base = list( ordered_stat.items_base)[0]\n",
    "        items_add = list(ordered_stat.items_add)[0]\n",
    "        confidence = ordered_stat.confidence\n",
    "        lift = ordered_stat.lift\n",
    "        support = record.support\n",
    "        result_dict = {\n",
    "            \"base_items\": items_base,\n",
    "            \"add_items\": items_add,\n",
    "            \"support\": support,\n",
    "            \"confidence\": confidence,\n",
    "            \"lift\": lift,\n",
    "        }\n",
    "        results.append(result_dict)\n",
    "\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second method to extract information without using a nested loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              base_items      add_items   support  confidence      lift\n",
      "0            Red Sparrow  Green Lantern  0.005733    0.300699  3.790833\n",
      "1              Star Wars  Green Lantern  0.005866    0.372881  4.700812\n",
      "2          Kung Fu Panda        Jumanji  0.015998    0.323450  3.291994\n",
      "3           Wonder Woman        Jumanji  0.005333    0.377358  3.840659\n",
      "4  The Spy Who Dumped Me    Spiderman 3  0.007999    0.271493  4.122410\n"
     ]
    }
   ],
   "source": [
    "# second method without second for loop\n",
    "results2 = []\n",
    "for record in association_results:\n",
    "    items_base = list(record.ordered_statistics[0].items_base)[0]\n",
    "    items_add = list(record.ordered_statistics[0].items_add)[0]\n",
    "    confidence = record.ordered_statistics[0].confidence\n",
    "    lift = record.ordered_statistics[0].lift\n",
    "    support = record.support\n",
    "    result_dict = {\n",
    "        \"base_items\": items_base,\n",
    "        \"add_items\": items_add,\n",
    "        \"support\": support,\n",
    "        \"confidence\": confidence,\n",
    "        \"lift\": lift,\n",
    "    }\n",
    "    results2.append(result_dict)\n",
    "results2 = pd.DataFrame(results2)\n",
    "print(results2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aprioritest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
